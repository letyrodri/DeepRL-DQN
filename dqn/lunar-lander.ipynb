{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Lunar Lander "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution using DQN algorithm in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting the environment https://gym.openai.com/envs/LunarLander-v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las acciones posibles pidiendo el `action_space` al Entorno. Referencia: https://gym.openai.com/docs/#environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acciones:  Discrete(4)\n",
      "Estados:  Box(8,)\n"
     ]
    }
   ],
   "source": [
    "actions_len = env.action_space\n",
    "states_len = env.observation_space\n",
    "\n",
    "print(\"Acciones: \", actions_len)\n",
    "print(\"Estados: \", states_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un juego tomando acciones aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -1.0335167170634925\n"
     ]
    }
   ],
   "source": [
    "# Arranca de nuevo, resetea el entorno\n",
    "env.reset()\n",
    "total_reward = deque(maxlen=100)\n",
    "\n",
    "while(True):\n",
    "    # Muestra el entorno, lo dibuja\n",
    "    env.render()\n",
    "    \n",
    "    # Elije una acción aleatoria\n",
    "    action = random.randint(0,3)\n",
    "    \n",
    "    # Toma una acción\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    total_reward.append(reward)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "print(\"Reward: \",np.mean(total_reward))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        return random.randint(0,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \n",
    "    def __init__(self, maxlen=100):\n",
    "        self.maxlen = maxlen\n",
    "        self.buffer = queue(self.maxlen)\n",
    "        \n",
    "    def get(self):\n",
    "        select = random.randint(0,self.maxlen)\n",
    "        return self.buffer[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.replay =  ReplayBuffer()\n",
    "    \n",
    "    def sample():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def learn():\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the DQN Agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
